개요
웹캠을 통해 인식된 사용자의 동작에 맞춰 움직이는 로봇을 제작했다.

필요한 부품
- 아두이노 우노
- 마이크로 서보모터(SG90) 6개 (한쪽 팔에 3개씩 설치)
- 컴퓨터와 웹캠

제작 과정
1. 구글에서 제공하는 Teachable Machine 서비스를 이용해서, 사용자의 포즈를 인식하는 머신 러닝 프로젝트를 생성했다.
2. 만들어진 모델을 다운로드한 뒤, 웹사이트를 통해 포즈 인식 프로그램을 실행하게 했다.
3. 웹사이트에서 app.js 파일으로 소켓 통신을 해서, 포즈가 추정된 값을 전달했다.
4. app.js파일에서 아두이노로 시리얼 통신을 해서, 포즈가 추정된 값을 다시 전달했다.
5. 아두이노에서 전달받은 값에 따라 서보모터를 동작시켰다.

실행 방법
1. 아두이노 파일을 아두이노에 업로드한다
2. app.js와 index.html을 http로 배포한다. (본인은 netlify 서비스를 이용해서 배포했음.)
3. 아두이노를 컴퓨터와 USB에 연결한다.
4. node.js 12.13.1 버전을 설치한 후 app.js의 시리얼 포트 번호를 현재 아두이노의 포트 번호로 바꾼다.
5. app.js를 node.js를 통해 실행한다.
6. 배포한 웹사이트에 접속해서 웹캠을 연결한다.
7. start버튼을 누르면 웹캠 화면이 표시되면서 사용자의 포즈가 인식된다.